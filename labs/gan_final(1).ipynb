{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "85FbY75yzHPF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.optim import SGD, Adam\n",
        "from torch import nn\n",
        "import torch\n",
        "from typing import List\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms as tv\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm.notebook import tqdm\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from time import sleep\n",
        "from torchvision.models import vgg16, vgg16_bn, resnet50, resnet18\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import KMeans\n",
        "from collections import Counter\n",
        "from typing import Tuple\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "from __future__ import print_function\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6lBwxUnzMiU",
        "outputId": "c04d546a-fd22-416a-f96f-6fad59ee6e83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VBt2lW-xztDK"
      },
      "outputs": [],
      "source": [
        "ds_train = MNIST(root=\"data\", train=True, download=True, transform=transforms.Compose(\n",
        "        [transforms.Resize(64), transforms.ToTensor()]\n",
        "    ))\n",
        "\n",
        "ds_test = MNIST(root=\"data\", train=False, download=True, transform=transforms.Compose(\n",
        "       [transforms.Resize(64), transforms.ToTensor()]\n",
        "    ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "15V10e6YzOH2"
      },
      "outputs": [],
      "source": [
        "batch_size=128\n",
        "dl_train = DataLoader(ds_train, batch_size, shuffle=True, drop_last=True) # dataloader with full dataset \n",
        "\n",
        "dl_test = DataLoader(ds_test, batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#linear\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, noise_dim, img_dim):\n",
        "    super().__init__()\n",
        "    self.gen = nn.Sequential(\n",
        "        nn.Linear(noise_dim, 256),\n",
        "        nn.LeakyReLU(0.1),\n",
        "        nn.Linear(256, 512),\n",
        "        nn.LeakyReLU(0.1),\n",
        "        nn.Linear(512, img_dim),\n",
        "        nn.Tanh(),\n",
        "    )\n",
        "    \n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.gen(x)\n",
        "   \n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_features):\n",
        "        super().__init__()\n",
        "        self.disc = nn.Sequential(\n",
        "            nn.Linear(input_features, 128), #28*28*1?\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, images):\n",
        "        return self.disc(images)\n",
        "\n"
      ],
      "metadata": {
        "id": "BnyS10wy1iNo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_uncon(gen: Generator, disc: Discriminator, train_loader, num_epochs: int):\n",
        "  gen.train()\n",
        "  disc.train()\n",
        "  for e in range(num_epochs):\n",
        "    counter = 0\n",
        "    print(e, \"epoch\")\n",
        "    for (real_images, _) in dl_train:\n",
        "      counter += 1\n",
        "      real = real_images.view(-1, 64*64).to(device)\n",
        "      noise = torch.randn(batch_size, noise_dim).to(device)\n",
        "      fake = gen(noise)\n",
        "      disc_real = disc(real).view(-1)\n",
        "      lossD_real = loss(disc_real, torch.ones_like(disc_real))\n",
        "      disc_fake = disc(fake.detach()).view(-1)\n",
        "      lossD_fake = loss(disc_fake, torch.zeros_like(disc_fake))\n",
        "      lossD= (lossD_real + lossD_fake) / 2\n",
        "      disc.zero_grad()\n",
        "      lossD.backward(retain_graph=True)\n",
        "      opt_disc.step()\n",
        "      \n",
        "      output = disc(fake).view(-1)\n",
        "      lossG = loss(output, torch.ones_like(output))\n",
        "      gen.zero_grad()\n",
        "      lossG.backward()\n",
        "      opt_gen.step()\n",
        "    \n",
        "      if counter%20 == 0:\n",
        "        num_row = 2\n",
        "        num_col = 10\n",
        "        fig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
        "        for i in range(20):\n",
        "          ax = axes[i//num_col, i%num_col]\n",
        "          if i//num_col == 0:\n",
        "            ax.imshow(fake[i].detach().cpu().numpy().reshape(64,64), cmap='gray')\n",
        "          else:\n",
        "            ax.imshow(real_images[i%num_col].reshape(64,64), cmap='gray')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "00LrHQLV-0Jn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise_dim = 100 #128, 256\n",
        "img_dim = 64*64*1\n",
        "\n",
        "lr = 3e-4\n",
        "\n",
        "genlin = Generator(noise_dim, img_dim).to(device)\n",
        "disclin = Discriminator(img_dim).to(device)\n",
        "\n",
        "#initialize_weights(genlin)\n",
        "#initialize_weights(disclin)\n",
        "\n",
        "opt_gen = Adam(genlin.parameters(), lr=lr)\n",
        "opt_disc = Adam(disclin.parameters(), lr=lr)\n",
        "\n",
        "loss = nn.BCELoss()"
      ],
      "metadata": {
        "id": "hNZvNKsl4cdJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_uncon(genlin, disclin, train_loader=dl_train, num_epochs=6)"
      ],
      "metadata": {
        "id": "W8HwjXis4cmU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convolutional\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, noise_dim, img_channels, input_features_g):\n",
        "    super().__init__()\n",
        "\n",
        "    self.gen = nn.Sequential(\n",
        "        self._block(noise_dim, input_features_g*16, 4, 1, 0),\n",
        "        self._block(input_features_g*16, input_features_g*8, 4, 2, 1),\n",
        "        self._block(input_features_g*8, input_features_g*4, 4, 2, 1),\n",
        "        self._block(input_features_g*4, input_features_g*2, 4, 2, 1),\n",
        "        nn.ConvTranspose2d(input_features_g*2, img_channels, kernel_size=4, stride=2, padding=1),\n",
        "        nn.Tanh(),\n",
        "    )\n",
        "    \n",
        "  def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "          return nn.Sequential(\n",
        "              nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
        "              nn.BatchNorm2d(out_channels),\n",
        "              nn.ReLU(),\n",
        "          )   \n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.gen(x)\n",
        "    \n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, img_channels, input_features_d):\n",
        "        super().__init__()\n",
        "\n",
        "        self.disc = nn.Sequential(\n",
        "            nn.Conv2d(img_channels, input_features_d, kernel_size=4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            self._block(input_features_d, input_features_d*2, 4, 2, 1),\n",
        "            self._block(input_features_d*2, input_features_d*4, 4, 2, 1),\n",
        "            self._block(input_features_d*4, input_features_d*8, 4, 2, 1),\n",
        "            nn.Conv2d(input_features_d*8, 1, kernel_size=4, stride=2, padding=0),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    \n",
        "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "          return nn.Sequential(\n",
        "              nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
        "              nn.BatchNorm2d(out_channels),\n",
        "              nn.LeakyReLU(0.2),\n",
        "          )\n",
        "          \n",
        "    def forward(self, images):\n",
        "        return self.disc(images)\n",
        "\n",
        "def initialize_weights(model):#weights initialization\n",
        "  for m in model.modules():\n",
        "    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
        "      nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "\n",
        "\n",
        "                         "
      ],
      "metadata": {
        "id": "4XMz7f7O1k9M"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise_dim = 100 #64, 128, 256\n",
        "img_dim = 64*64*1\n",
        "\n",
        "input_features_g = 64\n",
        "input_features_d = 64\n",
        "img_channels = 1\n",
        "\n",
        "lr = 3e-4\n",
        "\n",
        "gen_conv = Generator(noise_dim, img_channels, input_features_g).to(device)\n",
        "disc_conv = Discriminator(img_channels, input_features_d).to(device)\n",
        "\n",
        "#initialize_weights(gen_conv)\n",
        "#initialize_weights(disc)cinv)\n",
        "\n",
        "opt_gen = Adam(gen_conv.parameters(), lr=lr, betas=(0.5, 0.999))#like in DCGAN paper\n",
        "opt_disc = Adam(disc_conv.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "loss = nn.BCELoss()"
      ],
      "metadata": {
        "id": "20Cb8J-b1ryD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_uncon(gen_conv, disc_conv, train_loader=dl_train, num_epochs=10)"
      ],
      "metadata": {
        "id": "WWsom3Ka1zOy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tETy5sp4b2hf"
      },
      "source": [
        "\n",
        "## How is this related to conditional models?\n",
        "\n",
        "When traininng a classical GAN, we sample the noise vectors from a distribution of our choice and have little control over what we'll generate. To help with that, we can add inject a **condition** e.g. the class of our sample, to the model.\n",
        "\n",
        "It is quite simple to achieve this. Discriminator and generator should have additional modules which process the condition (e.g. in the form of one-hot vector) into a vector of desired shape and concatenate this vector with the model input:\n",
        "* for $G$, concatenate label output with noise vector\n",
        "* for $D$, concatenate label output with the classified image (e.g. as an additional channel)\n",
        "\n",
        "## Task for you - implement a cGAN\n",
        "* implement two variants of generators / discriminators\n",
        "  * built with linear layers (+ activations, batchnorm, dropout, etc)\n",
        "  * built with convolutional layers  (+ activations, batchnorm, dropout, etc), except the final linear layer of the discriminator\n",
        "\n",
        "You can use the code below as a start:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VYlC-3G1w8J0"
      },
      "outputs": [],
      "source": [
        "#convolutional\n",
        "\n",
        "class CGenerator(nn.Module):\n",
        "  def __init__(self, noise_dim, img_channels, input_features_g, num_classes, img_size, embed_size):\n",
        "    super().__init__()\n",
        "    self.img_size = img_size\n",
        "    self.gen = nn.Sequential(\n",
        "        self._block(noise_dim+embed_size, input_features_g*16, 4, 1, 0),\n",
        "        self._block(input_features_g*16, input_features_g*8, 4, 2, 1),\n",
        "        self._block(input_features_g*8, input_features_g*4, 4, 2, 1),\n",
        "        self._block(input_features_g*4, input_features_g*2, 4, 2, 1),\n",
        "        nn.ConvTranspose2d(input_features_g*2, img_channels, kernel_size=4, stride=2, padding=1),\n",
        "        nn.Tanh(),\n",
        "    )\n",
        "    self.embed = nn.Embedding(num_classes, embed_size)\n",
        "\n",
        "  def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "          return nn.Sequential(\n",
        "              nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
        "              nn.BatchNorm2d(out_channels),\n",
        "              nn.ReLU(),\n",
        "          )   \n",
        "\n",
        "  def forward(self, x, labels):\n",
        "    embedding = self.embed(labels)[:x.shape[0]].unsqueeze(2).unsqueeze(3)\n",
        "    x = torch.cat([x, embedding], dim=1)\n",
        "    return self.gen(x)\n",
        "\n",
        "\n",
        "class CDiscriminator(nn.Module):\n",
        "    def __init__(self, img_channels, input_features_d, num_classes, img_size):\n",
        "        super().__init__()\n",
        "        self.img_size = img_size\n",
        "        self.disc = nn.Sequential(\n",
        "            nn.Conv2d(img_channels+1, input_features_d, kernel_size=4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            self._block(input_features_d, input_features_d*2, 4, 2, 1),\n",
        "            nn.Conv2d(input_features_d*2, 1, kernel_size=7, stride=2, padding=0),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.embed = nn.Embedding(num_classes, img_size*img_size)\n",
        "    \n",
        "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "          return nn.Sequential(\n",
        "              nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
        "              nn.BatchNorm2d(out_channels),\n",
        "              nn.LeakyReLU(0.2),\n",
        "          )\n",
        "          \n",
        "    def forward(self, x, labels):\n",
        "        embedding = self.embed(labels).view(x.shape[0], 1 ,self.img_size, self.img_size)\n",
        "        x = torch.cat([x, embedding], dim=1)\n",
        "        return self.disc(x)\n",
        "\n",
        "def initialize_weights(model):#weights initialization\n",
        "  for m in model.modules():\n",
        "    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
        "      nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "\n",
        "\n",
        "                         \n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fYVVhNV95tcg"
      },
      "outputs": [],
      "source": [
        "input_features_g = 64\n",
        "input_features_d = 64\n",
        "\n",
        "noise_dim = 128 #64, 128, 256\n",
        "img_dim = 64*64*1\n",
        "img_size = 64\n",
        "img_channels = 1\n",
        "num_classes = 10\n",
        "gen_embedding = 256\n",
        "\n",
        "lr = 2e-4\n",
        "\n",
        "gen_cond = CGenerator(noise_dim, img_channels, input_features_g, num_classes, img_size, gen_embedding).to(device)\n",
        "disc_cond = CDiscriminator(img_channels, input_features_d, num_classes, img_size).to(device)\n",
        "\n",
        "initialize_weights(gen_cond)\n",
        "initialize_weights(disc_cond)\n",
        "\n",
        "opt_gen = Adam(gen_cond.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "opt_disc = Adam(disc_cond.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "loss = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Gz9Mf8l6xLKF"
      },
      "outputs": [],
      "source": [
        "def train(gen: CGenerator, disc: CDiscriminator, train_loader, num_epochs: int):\n",
        "  disc.train()\n",
        "  gen.train()\n",
        "  for e in range(num_epochs):\n",
        "    print(e, \"epoch\")\n",
        "    counter = 0\n",
        "    for (real_images, labels) in dl_train:\n",
        "      counter += 1\n",
        "      real = real_images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      noise = torch.randn(batch_size, noise_dim, 1, 1).to(device)\n",
        "      fake = gen(noise, labels)\n",
        "      disc_real = disc(real, labels).view(-1)\n",
        "      lossD_real = loss(disc_real, torch.ones_like(disc_real))\n",
        "      disc_fake = disc(fake.detach(), labels.detach()).view(-1)\n",
        "      lossD_fake = loss(disc_fake, torch.zeros_like(disc_fake))\n",
        "      lossD= (lossD_real + lossD_fake) / 2\n",
        "      disc.zero_grad()\n",
        "      lossD.backward(retain_graph=True)\n",
        "      opt_disc.step()\n",
        "      \n",
        "      output = disc(fake, labels).view(-1)\n",
        "      lossG = loss(output, torch.ones_like(output))\n",
        "      gen.zero_grad()\n",
        "      lossG.backward()\n",
        "      opt_gen.step()\n",
        "    \n",
        "      if counter%20 == 0:\n",
        "        num_row = 2\n",
        "        num_col = 10\n",
        "        fig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
        "        for i in range(20):\n",
        "          ax = axes[i//num_col, i%num_col]\n",
        "          if i//num_col == 0:\n",
        "            ax.imshow(fake[i].detach().cpu().numpy().reshape(64,64), cmap='gray')\n",
        "          else:\n",
        "            ax.imshow(real_images[i%num_col].reshape(64,64), cmap='gray')\n",
        "\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXfC6Fcf8vTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7e0637d-d762-46c1-92b1-2a6cacd1b2d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 epoch\n"
          ]
        }
      ],
      "source": [
        "train(gen_cond, disc_cond, train_loader=dl_train, num_epochs=400)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sytImeW8d4CL"
      },
      "source": [
        "## Task - draw example samples from the trained models\n",
        "* for each digit class, sample an image\n",
        "* for each image sample, add the title with the digit which served as a conditioning vector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgbVY9pMxQ4v"
      },
      "outputs": [],
      "source": [
        "\n",
        "noise = torch.randn(batch_size, noise_dim, 1, 1).to(device)\n",
        "num_row = 1\n",
        "num_col = 10\n",
        "\n",
        "fig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
        "for label in range(10):\n",
        "  label = torch.tensor(label)\n",
        "  lista = []\n",
        "  for i in range(batch_size):\n",
        "    lista.append(int(label))\n",
        "  labels = torch.tensor(lista).to(device)\n",
        "  with torch.no_grad():\n",
        "    fake = gen_cond(noise, labels)\n",
        "\n",
        "    ax = axes[label]\n",
        "    ax.imshow(fake[0].detach().cpu().numpy().reshape(64,64), cmap='gray')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B668JYy_euw0"
      },
      "source": [
        "## Task - draw a couple of examples of interpolation between classes:\n",
        "For a fixed noise vector, choose two classes and draw samples generated from this noise vector and one-hot vectors of two classes gradually transitioning between the two classes. \n",
        "\n",
        "Please print or otherwise indicate which two classes you are transitioining between."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}